# Evaluation of a clustering scheme

Evaluation of a clustering scheme is related only to the result of the clustering, not to the clustering technique itself

since clustering in not supervised, evaluation is more difficult

- we don't have a ground truth to compare with to abtain a notion of error/loss

we need one or more score function to measure various properties of the clusters and of the clustering scheme as a whole

- ad esempio, vorremmo uno score utile a capire il parametro k in k-means

# Cohesion and separation measures

## SSE

SSE/SSW misura la **coesione dei cluster**: quanto ogni punto è vicino al centro del suo cluster.

- SSE alto significa cluster poco compatti

## Sum of Squares Between clusters (SSB)

Misura quanto i centroidi dei cluster sono lontani dal centroide globale del dataset

- è una **misura della separazione tra cluster**
- SSB alta → i cluster sono molto lontani tra loro → buona separazione
- SSB bassa → i cluster sono vicini → separazione debole o cluster molto simili

## Total Sum of Squares (TSS)

sum of squared distances of the points from the global centroid

- **NB**: al contrario delle due misure precedenti **non dipende dal clustering scheme**, è una proprietà del dataset

TSS misura la **sparsity of the dataset**

- TSS alta, abbiamo datapoints molto sparsi rispetto al centro
- TSS bassa, abbiamo datapoints molto vicini al centro

**NB**: vale sempre che: TSS = SSE + SSB

Thus, a good clustering scheme:

- deacreses (minimizes) SSE -> minimizes intracluster sparsity
- and this increases (maximizes) SSB -> maximizes cluster separation
- **basta farne uno e l'altro viene da se: miminize SSE == maximize SSB**

# Silhouette score as a score for evaluation of a clustering scheme

Requirements for a clustering quality score:

- values are in a standard range, e.g. \[-1, 1]
- increases with the separation between clusters
- decreases for clusters with low cohesion or, in other words, with high sparsity

Notiamo che la distorsione non è una misura adatta per valutare un clustering

- it doesn't have an upper bound
- it doesn't take into account separation between clusters
- it INCREASES for clusters with low cohesion
- if we tried to measure clusters with high cohesion, the distorsion would always get lower with a larger number of clusters

Silhouette score è invece un buon clustering quality score:

- Considers the INDIVIDUAL contribution of each object, say xi, to cluster sparsity and separation from other clusters
  - **ogni datapoint ha quindi un suo silhouette score**
- For the global score of a cluster/clustering scheme compute the average score over the cluster/dataset

**Intuition**:

- when a datapoint has a score less than zero, it means that there is a dominance of objects in other clusters at a distance smaller than objects of the same cluster
  - punti di altri cluster sono più simili a punti del mio cluster
  - sparsity domina
- altrimenti, il contrario
  - separation domina

Viene da se che vogliamo un silhouette score positivo più grande possibile

**NB**: elbows in the graph of inertia are a suggestion that that number of clusters is significant

- inizialmente la distorsione cala velocemente dato che otteniamo facilmente vari cluster molto separati (ricorda che massimizzare la coesione è uguale a massimizzare la separazione)
- quando la distorsione comincia a calare meno velocemente, significa che i nuovi cluster sono meno separati
- one of these elbow points is frequently a plausible value for K

## Looking for the best number of clusters | elbow method

silhouette score seems more promising but it's more computationally intensive

inizialmente possiamo usare l'elbow method con SSE

se non c'è un clear elbow possiamo passare a silhouette score

se silhouette score sono simili con varie configurazioni, una buona idea è considerare la configurazione con la distorsione minore

# Partial supervision with gold standard

partition è un termine che crea confusione

**il gold standard è un clustering scheme implementato da un insieme di etichette per ogni punto del dataset**

perchè usare il gold standard? To validate a clustering technique which can be applied later to new, unlabelled data

- confrontiamo il mio clustering scheme con quello del gold standard per capire se sto raggruppando bene o male
- una volta trovato un clustering scheme soddisfacente secondo il mio gold standard applico questo schema ad altri dataset sperando di ottenere risultati altrettanto buoni
  - simile a quello che si fa in supervised learning con un test set

Frase originale:

"the cardinalities of the sets of distinct labels generated by the two schemes Vg and Vk can be different, and also in case of identity of the two grouping schemes, a permutation of labels could be necessary to make them equal"

Significato:

Hai due tipi di etichettatura (raggruppamento) dei dati:

- yg = gold standard (etichettamento vero, di riferimento)
- yk = risultato del clustering (etichettamento ottenuto automaticamente)
- Vg e Vk sono gli insiemi delle etichette uniche in ciascuno schema.

Esempio:

- gold standard ⇒ {A, B, C}
- clustering ⇒ {1, 2}

Qui le cardinalità possono essere diverse:

- 3 contro 2.
- se questo è il caso non posso confrontare con il gold standard
- infatti (immagino) se posso decidere il numero di cluster lo imposto a quello del gold standard

Anche se i due raggruppamenti sono identici ma usano etichette diverse, bisogna comunque ripermermutare (rimappare) le etichette perché i nomi non coincidono.

Esempio:

- gold standard: {A, A, B, B}
- clustering: {1, 1, 2, 2}

I gruppi sono gli stessi, ma le etichette non corrispondono. Basta rinominare 1→A e 2→B per farle diventare confrontabili.

## Similarity oriented measures

Consider a clustering scheme yk(.) and compare it with the Gold Standard yg(.), consideriamo tutte le coppie di datapoint e recuperiamo i seguenti count:

- SGSK if they belong to the same set in yg(.) and yk(.)
- SGDK if they belong to the same set in yg(.) and not in yk(.)
- DGSK if they belong to the same set in yk(.) but not in yg(.)
- DGDK if they belong to different sets both in yg(.) and yk(.)

A questo punto possiamo utilizzare vari score per confrontare i due clustering scheme **anche se il numero di cluster tra gold standard e il mio clustering è diverso**:

- RAND score
- Jaccard coefficient
